---
title: "STAT 892 - Final Paper"
author: Ryan Lalicker
date: today
date-format: long
abstract: |
  WRITE ABSTRACT BEFORE SUBMITTING  (@test) (@lauer)
execute: 
  echo: false
  warning: false
columns: 2
format:
  pdf:
    fig-align: center
    fig-width: 6
    fig-height: 4
bibliography: references.bib
editor: 
  markdown: 
    wrap: sentence
---

```{r}
#| label: fig-set-up
#| echo: false
#| eval: true

# Add all necessary libraries here.
library(ggplot2)
library(dplyr)
library(knitr)
library(kableExtra)

# Datasets used.
covid <- read.csv("2020 US Covid Deaths.csv")

```

```{r}
#| label: fig-scratch-work
#| echo: false
#| eval: false

# Any work done in R that should not be ran as part of the paper can go here.
## EX: How many unique entires in a dataset.


```

# Introduction

Many areas of research rely on visualizations to express their findings to both experts in the field and the general public alike.
This applies to other areas of life as well such as news, entertainment, and public health that reach the largest audience possible with easily-digestible visualizations and quick explanations over in-depth, domain specific reports.
(@Unwin2020Why).
Although this practice goes back many centuries (@firstplot), in today's fast moving-technology driven world creating visualizations has never been easier.
Yet, visualizations need to be effective in order to have the desired outcome of educating the public.

A key issue in creating effective visualizations is that of bias.
Sometimes bias comes from the presenter of information.
Mistakes in visualizations can lead others to draw the wrong conclusions.
Other times, the presenter may take advantage of an audience's trust to mislead them with purposely biased plots.
Bias does not come from just the presenter though.
Audience members with long-held beliefs on certain subjects may resist new information that contradicts their previous opinion.

Another issue with effectively communicating through visualization is audience understanding.
While good visualizations are meant to be accessible, sometimes the best way to show data can be largely unknown to the public.
This diminishes the effect of the visualization.

In this paper I will propose an experiment with the intent to account for several facets of audience interactions with plots.
The experiment will measure how a general audience perceives biased plots versus more neutral plots while measuring performance across different plot types and topics.
The files used in the paper can be found [here](https://github.com/RyanLalicker/STAT-892-Final).

# Motivation

To understand how bias can show up in creating and interpreting visualizations we first need to discuss what makes an effective visualization.
In my opinion the components of effective visualizations can be grouped into two categories: accurate representations of the data and making a visualization readable for the public.
The former is an ethical responsibility for a researcher since, whether intentional or not, misleading or outright false visualizations hinder the true findings of the research.
The second category has many components to it.
These include taking into account accessibility concerns such as avoiding plots based in red and green together and ensuring axes and labels are readable for the viewer.
Note, the latter point falls into both categories.

Perhaps the greatest challenge of making effective visualizations is considering the public's graphical literacy.
An example of this occurred during the first year of the COVID-19 pandemic.
Many American media outlets chose to use a logarithmic scale to illustrate the total number of deaths.
As seen in @fig-covid, the logarithmic scale on the right does a better job of showing how the rate of deaths is changing than the linear scale on the left.
However, a study by @logCovid found on average both experienced scientists and the general public that took part in the study understand the linear scale far more than the logarithmic scale.
This is likely due to a lack of experience with log functions and illustrates how choosing the plot that one feels best represents the data is not always the one an audience understands.

```{r,,fig.pos="H"}
#| label: fig-covid
#| echo: false
#| eval: true
#| fig-cap: "COVID-19 deaths in the United States. Data from Febrary 9 through April 18, 2020.  Data provided by @COVIDdeaths."
#| layout-ncol: 2
#| fig-subcap: 
#|  - "Linear scale"
#|  - "logarithmic scale"
#| fig-width: 6
#| fig-height: 4


covid$End.Date <- as.Date(covid$End.Date, format = "%m/%d/%Y")

covid_filtered <- covid %>% 
  filter(End.Date >= "2020-02-09") %>%
  filter(End.Date <= "2020-04-18")

covid_filtered2 <- covid_filtered %>%
  mutate(COVID.19.Deaths = if_else(End.Date < "2020-02-29", NA, COVID.19.Deaths))

ggplot(covid_filtered, aes(x = End.Date, y = COVID.19.Deaths)) +
  geom_line(color = "dodgerblue2", size = 1) + # Line properties
  labs(
    x = "Date in 2020",
    y = "COVID-19 Deaths"
  ) +
  theme_minimal()

ggplot(covid_filtered2, aes(x = End.Date, y = log(COVID.19.Deaths))) +
  geom_line(color = "dodgerblue2", size = 1) + # Line properties
  labs(
    x = "Date in 2020",
    y = "Log of COVID-19 Deaths"
  ) +
  ylim(0, 12) +
  theme_minimal()

```

The example above shows how the creator of a visualization can do what they believe is right and still have difficulty getting their point across due to audience misunderstanding.
One element I want to look at is what types of basic visualizations do people understand best.
While it seems likely the public would struggle to understand non-linear scales, knowing how pie charts compare to bar charts in terms of audience understanding would be useful.

The main focus of this experiment, however, is how the public perceives misleading visualizations compared to accurate plots.
These misleading visualizations can of course be honest mistakes by the creator or publisher of the visualization, but in some cases it may be intentionally.
Some of the ways this can happen include ill-fitting chart types, the y-axis not starting at zero, data being plotted incorrectly, or even exaggerated plot and axis titles.
When plots exhibiting one or more of these issues are published, viewers could consider the misleading information factual, which presents many problems for society.

An example of this is in the plot below which shows the unemployment rate through the year 2011.
The photo was taken from a segment aired by Fox News.
This plot is misleading in two ways.
First, the y-axis goes from 8% to 10%, leading to any changes in the unemployment rate from one month to another to be more pronounced.
Additionally, the November percentage of 8.6%, which appears to be the lowest of the year, is instead shown to be equivalent to the previous month's percentage of 9.0%.
(@misleading).

![Plot of 2011 unemployment rate with misleading y-axis. Published by Fox News in 2011.](fox-bad-graph.png){width="3.5in" #fig-fox}

While this plot is not necessarily intentionally misleading, one could easily walk away with an opinion not supported by the underlying data.
It is also important to keep in mind the timing and source as well.
Economic issues were among the key issues Americans were concerned about following the Great Recession.
This means plots that make the economic situation seem worse than it is could have negative consequences.
(@gallup).
On top of this, Fox News averaged 1.87 million prime-time viewers for the year 2011, meaning many people could have been mislead at once.
(@TimesHerald).

Knowing how the public perceives misleading graphics as compared to good graphics can give researchers a way to quantify the effects of misinformation.
Previous work, such as that by @lauer did this while controlling for the plot type.
While the researchers attempted to account for potential biases from the creators of visualizations through mixing biased and unbiased plots in the experiment, they purposely avoided the other place bias can come from: the viewer.
The researchers made all plots related to noncontroversial topics.

In this experiment I will account for potential audience bias by both including plot topics that are considered controversial along with noncontroversial topics and by taking demographic information from each participant.
Both groups of topics will have a mix of biased and unbiased plots, as well as different types of graphs.
Together, this will allow one to see how audience members with different opinions evaluate different types of graphics depending on the sensitivity of the topic and whether they can detect misleading information.

# Literary Review

As previously alluded to, the main inspiration for this experiment comes from @lauer.
Their experiment showed each participant four different kinds of plots in a random order.
These plots were a bar chart, a line graph, a pie chart, and a bubble graph.
Each plot had a deceptive version and a nondeceptive version, called the control, based on the same data.
Note, the deceptive plot used many of the tactics discussed previously in this paper.
On top of the plots themselves, two titles for each topic were written, again with one being deceptive and one not.
This made it so each graph type had four different possible ways to be presented.
As previously mentioned, the researchers intentionally chose noncontroversial topics.

The participants were then asked a questions about their perception of each plot and provided answers on a scale from one to six.
These questions focused on potential changes or differences from one state to another.
This allowed for a lower score to indicate a small change, while larger scores corresponded to larger changes.
After completing a question for each of the four plot types, participants were then asked to rank the graphs from easiest to hardest to understand and finally state how comfortable they were with each plot type through multiple choice questions.

In total, the experiment had 329 participants.
These participants were either first-year students in psychology classes at Arizona State University or instructors in similar fields at different universities.
While this was convenient for the researchers, it is unlikely this group is representative of the population at large, since all participants are either college students or faculty.

The results of the plot interpretation are shown in @fig-lauer-results.
(@lauer, pg.333).
In each plot type, the largest average scores, which again indicate the greater perceived change from one state to another, come from the deceptive plots.
This gap is somewhat pronounced in all plot types except the bubble graphs.
Meanwhile, exaggerated plot titles seems to have played far less of a role in participant answers.
This could suggest that viewers are better equipped to disregard poor headlines than poor graphs.

![Mean responses to graphs in the experiment by @lauer.](old-study-results.png){#fig-lauer-results}

While attempting to replicate the title effect would be interesting, for this experiment I will not be focusing on plot titles.
In its place, each plot type will have a deceptive and control plot related to a controversial topic with a neutral headline for all plots.
This is what I believe the experiment by @lauer is lacking in regards to my own research interests of the role bias plays in the perception of visualizations.

For a better understanding of how to conduct an experiment that measured bias I considered a study by @schwalbe2024.
The study was focused on how American individuals from different backgrounds perceive headlines and corresponding articles.
Half of the articles were nonpolitical while the other half were all related to Donald Trump.
These articles were graded on a scale from against to for Trump.
The participants were shown an equal number of each.
The articles were also real news, fake news, and a mix of both in equal numbers.

Participants were asked questions about the articles.
These included whether the article was truthful and if they would share it with others.
These answers taken on a five-point scale ranging from negative to positive.
At the end of the study participants were asked several demographic questions, including their opinions of Donald Trump on a seven-point scale.
On this scale a one implied strong opposition, a four was neutral, and a seven was strong support.
Researchers chose to combine participants with scores of one to three in one group, five to seven in another, and leave scores of four as their own category.

For the articles involving Trump, researchers labeled cases concordant when the article skew matched the participants beliefs and discordant when they did not.
Researchers used these labels along with participant answers to generate a political bias score.
The results of this metric highlight the importance of this research as the authors found real news was more effected by bias than fake news.

Participants were recruited through a platform called Lucid.
The service used quota sampling based off demographic targets to find participants on multiple websites.
Researchers used quota sampling to ensure their sample reflected the U.S.
Census for many demographic variables.
2,180 participants were recruited, though 371 were excluded for failing to follow survey rules or missing attention checks built into the survey.

While this study focused on articles instead of visualizations, it shows ways of measuring bias that I believe could be applied to a graphics study.
Additionally, quota sampling presents an interesting approach to building a sample.

# Experimental Methods

### Sets of Plots

The survey used in this experiment will consist of two sets of plots: one set related to noncontroversial topics and one for controversial topics.
For simplicity the controversial topics will be related to politics, health, or the environment.
Specifically, the topics will be chosen if they tend to be interpreted differently based on ones position on the left-right political spectrum.
The noncontroversial set will focus on topics less likely to fit onto this spectrum.
The topics in both sets should be based in the country of the participants in an attempt to mimic a visualization they could see in their daily lives.
For the purpose of this paper we can assume the participants are all living in the United States.

```{r,,fig.pos="H"}
#| label: fig-topics
#| echo: false
#| eval: true
#| fig-cap: "Potential topics used for generating plots sorted into the sets outlined in the paper."

topics <- data.frame(
  Noncontroversial = c("Movies from a particular studio in a year",
              "Graduation rates at public universities", 
              "Ticket sales of  minor league baseball team",
              "Adoption rates at a pet shelter"),
  Controversial = c("Changes in unemployment rate",
           "Government spending",
           "Changes in average temperatures over time",
           "Gun deaths in a major city")
)

kable(topics)

```

Some examples of potential topics are shown in @fig-topics.
Plots related minor league baseball teams and pet adoptions in a random U.S. town are unlikely to come with the prior biases that accompany climate change or gun violence visualizations.
One key point related to some of the controversial takes is timing.
In terms of where answers fall on a political spectrum, opinions on a statistic like the unemployment rate change based on who is in power.
This implies that the survey portion of the experiment should not take place between a national election and the inauguration of any new president or congress.

### Plot Types

For this experiment, participants will be shown four types of graphs.
These will be bar charts, line plots, pie charts, and bubble graphs.
Each chart type will appear once per set in a random order.
As was the case in the experiment by @lauer, each plot will have a control version and a deceptive version.
The version shown to the audience will be decided through randomization.

The control and deceptive plots must follow certain guidelines.
For bar charts, the control graphs must have an equal width for each bar and an axis that starts at zero.
While there are many ways to make a deceptive bar chart, this experiment will focus on a y-axis starting at some number other than zero.
@fig-bar shows the ticket sales for a fictional minor league baseball team in 2018 and 2023.
In the control plot, the y-axis starts at zero and goes to \$15,000.
The y-axis of the deceptive plot not only starts at \$11,00, but also stops at \$14,000.  Visually this suggests the ticket sales increased by a factor of three or four instead of the 12.5% increase that actually occurred.

```{r,,fig.pos="H"}
#| label: fig-bar
#| echo: false
#| eval: true
#| fig-cap: "Example of a bar chart related to ticket sales of a fictional AAA baseball team in 2018 and 2023."
#| layout-ncol: 2
#| fig-subcap: 
#|  - "Control"
#|  - "Deceptive"
#| fig-width: 6
#| fig-height: 4

RubberDucks <- data.frame(
  Year = c("2018", "2023"),
  Sales = c(12000, 13500)
)

ggplot(RubberDucks, aes(x = Year, y = Sales)) +
  geom_bar(stat = "identity", color = "skyblue", fill = "skyblue") + coord_cartesian(ylim = c(0, 15000)) +
  labs(title = "Ticket Sales for AAA Baseball Team",
       x = "Year",
       y = "Tickets Sold") +
  theme_minimal()

ggplot(RubberDucks, aes(x = Year, y = Sales)) +
  geom_bar(stat = "identity", color = "skyblue", fill = "skyblue") + coord_cartesian(ylim = c(11500, 14000)) +
  labs(title = "Ticket Sales for AAA Baseball Team",
       x = "Year",
       y = "Tickets Sold") +
  theme_minimal()
```

The line plots will follow the same guideline as the bar graphs.
Control plots will start have the y-axis beginning at zero while deceptive plots will have an altered y-axis to make changes from one time point to another seem larger.  
An example of the deceptive plot can be found in @fig-fox, while @fig-line shown later on is a control plot. **VERIFY THIS.**
Note, the data points will be plotted correctly for all line plots, unlike in @fig-fox.

**DOUBLE CHECK THIS BEFORE SUBMITTING**






```{r,,fig.pos="H"}
#| label: fig-pie
#| echo: false
#| eval: true
#| fig-cap: ""
#| layout-ncol: 2
#| fig-subcap: 
#|  - "Control"
#|  - "Deceptive"
#| fig-width: 6
#| fig-height: 4

control_movies <- data.frame(
  Genre = c("Action", 
            "Romance",
            "Thriller", 
            "Sci-Fi", 
            "Western", 
            "Epic"),
  Percentage = c(28, 23, 22, 
                 13, 10, 4)
)
28+23+22+13+10
deceptive_movies <- data.frame{
  Genre = c("Action", "Romance", "Thriller", "Sci-Fi", "Western", "Epic")
  Percentage = c(39, 28, 25, 5, 2, 1)
}




```





```{r,,fig.pos="H"}
#| label: fig-bubble
#| echo: false
#| eval: true
#| fig-cap: ""
#| layout-ncol: 2
#| fig-subcap: 
#|  - "Control"
#|  - "Deceptive"
#| fig-width: 6
#| fig-height: 4

```


### Plot Questions



```{r,,fig.pos="H"}
#| label: fig-line
#| echo: false
#| eval: true
#| fig-cap: ""
#| layout-ncol: 2
#| fig-subcap: 
#|  - "Control"
#|  - "Deceptive"
#| fig-width: 6
#| fig-height: 4

```


### Demographic Questions






# Data Collection

# Analysis Plan

# Potential Flaws and Improvements

# Conclusion

\newpage

# References

::: {#refs}
:::

\newpage

# Appendix A: R Code

```{r}
#| label: appendix-A
#| echo: true
#| eval: false



```

\newpage

# Appendix B: AI Prompts and Answers

**Prompt:** How many R's are in the word strawberry?

**Answer:** The word strawberry contains three R's.
